{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe2f4522",
   "metadata": {},
   "source": [
    "# 1.Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad45b87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x247356bcd50>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "import concurrent.futures\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8df274b",
   "metadata": {},
   "source": [
    "# 2.Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "889281eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_client_data(data_dir, client_type, idx, img_size=28):\n",
    "    X, y = [], []\n",
    "    folder = os.path.join(data_dir, f\"{client_type}_{idx}\")\n",
    "    for label in os.listdir(folder):\n",
    "        label_folder = os.path.join(folder, label)\n",
    "        if not os.path.isdir(label_folder):\n",
    "            continue\n",
    "        for fname in os.listdir(label_folder):\n",
    "            if fname.endswith('.png') or fname.endswith('.jpg'):\n",
    "                img = Image.open(os.path.join(label_folder, fname)).convert('L').resize((img_size, img_size))\n",
    "                X.append(np.array(img).flatten() / 255.0)\n",
    "                y.append(label)\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.float32)\n",
    "\n",
    "def load_mnist_binary_test_data_flat(test_dir, img_size=28):\n",
    "    X = []\n",
    "    y = []\n",
    "    if not os.path.exists(test_dir):\n",
    "        return X, y\n",
    "    for label in ['0', '1']:\n",
    "        label_folder = os.path.join(test_dir, label)\n",
    "        if not os.path.isdir(label_folder):\n",
    "            continue\n",
    "        for fname in os.listdir(label_folder):\n",
    "            if fname.endswith('.png') or fname.endswith('.jpg'):\n",
    "                img = Image.open(os.path.join(label_folder, fname)).convert('L').resize((img_size, img_size))\n",
    "                X.append(np.array(img).flatten() / 255.0)\n",
    "                y.append(label)\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    y = np.array(y, dtype=np.float32)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473a4c3e",
   "metadata": {},
   "source": [
    "# 3.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88a1413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 1)\n",
    "        self.fc2 = nn.Linear(1, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a40aa727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MNISTNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.fc1 = nn.Linear(28*28, 1)\n",
    "#     def forward(self, x):\n",
    "#         x = self.fc1(x)\n",
    "#         x = torch.sigmoid(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096e6300",
   "metadata": {},
   "source": [
    "# 4.Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd29671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(pred, target):\n",
    "    eps = 1e-7\n",
    "    pred = torch.clamp(pred, eps, 1 - eps)\n",
    "    return -(target * torch.log(pred) + (1 - target) * torch.log(1 - pred)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf17a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_local_worker(args):\n",
    "    X_c_tensor, y_c_tensor, global_weights, learning_rate, local_epoch, experiment_bs, device = args\n",
    "    model = MNISTNet().to(device)\n",
    "    model.load_state_dict(global_weights)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "    for epoch in range(local_epoch):\n",
    "        for start in range(0, X_c_tensor.size(0), experiment_bs):\n",
    "            end = start + experiment_bs\n",
    "            xb = X_c_tensor[start:end]\n",
    "            yb = y_c_tensor[start:end]\n",
    "            outputs = model(xb)\n",
    "            preds = (outputs >= 0.5).float()\n",
    "            loss = binary_cross_entropy(outputs, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    # Return a deepcopy to avoid issues with state_dict references\n",
    "    return copy.deepcopy(model.state_dict()), X_c_tensor.size(0), yb, outputs, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8db3e2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def average_weights(w_list):\n",
    "    avg = {}\n",
    "    for k in w_list[0].keys():\n",
    "        avg[k] = sum([w[k] for w in w_list]) / len(w_list)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f5df39",
   "metadata": {},
   "source": [
    "# 5.Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66763e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_HONEST = 100\n",
    "N_POISONED = 100\n",
    "IMG_SIZE = 28\n",
    "LEARNING_RATE = 0.001\n",
    "ROUNDS = 20\n",
    "LOCAL_EPOCHS = 1\n",
    "BATCH_SIZE = 1\n",
    "N_CLASSES = 2\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DATA_PATH = \"./data/mnist_binary_poison/train\"\n",
    "TEST_PATH = \"./data/mnist_binary_poison/test\"\n",
    "\n",
    "RESULT_PATH = \"./results\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6888dfd7",
   "metadata": {},
   "source": [
    "# 6.Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "886592d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding poison n: 0 for percent: 0\n",
      "Adding poison n: 12 for percent: 10\n",
      "Adding poison n: 25 for percent: 20\n",
      "Adding poison n: 43 for percent: 30\n",
      "Adding poison n: 67 for percent: 40\n",
      "Adding poison n: 100 for percent: 50\n",
      "Poison n list: [0, 12, 25, 43, 67, 100]\n"
     ]
    }
   ],
   "source": [
    "poison_percent = [0, 10, 20, 30, 40, 50]\n",
    "poison_n_list = []\n",
    "for p in range(0,N_POISONED+1):\n",
    "    percent = int((p / (p+N_HONEST)) * 100)\n",
    "    if percent in poison_percent:\n",
    "        poison_percent.remove(percent)\n",
    "        print(f\"Adding poison n: {p} for percent: {percent}\")\n",
    "        poison_n_list.append(p)\n",
    "print(\"Poison n list:\", poison_n_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "438c0487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poison_percent 0 round 0: loss_train=0.6359, acc_train=0.4300, loss_test=0.5890, acc_test=0.5000\n",
      "poison_percent 0 round 1: loss_train=0.4673, acc_train=0.5200, loss_test=0.4863, acc_test=0.5000\n",
      "poison_percent 0 round 2: loss_train=0.4789, acc_train=0.4700, loss_test=0.4427, acc_test=0.5000\n",
      "poison_percent 0 round 3: loss_train=0.4477, acc_train=0.4700, loss_test=0.4198, acc_test=0.5000\n",
      "poison_percent 0 round 4: loss_train=0.4692, acc_train=0.4300, loss_test=0.4049, acc_test=0.5000\n",
      "poison_percent 0 round 5: loss_train=0.3492, acc_train=0.5500, loss_test=0.3932, acc_test=0.5000\n",
      "poison_percent 0 round 6: loss_train=0.3486, acc_train=0.5300, loss_test=0.3827, acc_test=0.5000\n",
      "poison_percent 0 round 7: loss_train=0.4188, acc_train=0.4300, loss_test=0.3737, acc_test=0.5000\n",
      "poison_percent 0 round 8: loss_train=0.3140, acc_train=0.8600, loss_test=0.3651, acc_test=0.9551\n",
      "poison_percent 0 round 9: loss_train=0.3072, acc_train=0.9500, loss_test=0.3567, acc_test=0.9597\n",
      "poison_percent 0 round 10: loss_train=0.3553, acc_train=0.9600, loss_test=0.3483, acc_test=0.9622\n",
      "poison_percent 0 round 11: loss_train=0.3744, acc_train=0.9300, loss_test=0.3408, acc_test=0.9628\n",
      "poison_percent 0 round 12: loss_train=0.3325, acc_train=0.9500, loss_test=0.3322, acc_test=0.9653\n",
      "poison_percent 0 round 13: loss_train=0.3272, acc_train=0.9800, loss_test=0.3243, acc_test=0.9663\n",
      "poison_percent 0 round 14: loss_train=0.3533, acc_train=0.9500, loss_test=0.3167, acc_test=0.9673\n",
      "poison_percent 0 round 15: loss_train=0.2804, acc_train=0.9400, loss_test=0.3095, acc_test=0.9679\n",
      "poison_percent 0 round 16: loss_train=0.3271, acc_train=0.9500, loss_test=0.3016, acc_test=0.9709\n",
      "poison_percent 0 round 17: loss_train=0.3354, acc_train=0.9500, loss_test=0.2938, acc_test=0.9719\n",
      "poison_percent 0 round 18: loss_train=0.3099, acc_train=0.9700, loss_test=0.2859, acc_test=0.9724\n",
      "poison_percent 0 round 19: loss_train=0.2694, acc_train=0.9700, loss_test=0.2790, acc_test=0.9740\n",
      "Training log saved to ./results\\FL_MODEL_N1L2_BATCH_SIZE1\\mnist_binary_random_data\\poisoned_0percent\\poisoned_0percent.csv\n",
      "poison_percent 10 round 0: loss_train=0.5379, acc_train=0.8839, loss_test=0.5218, acc_test=0.8954\n",
      "poison_percent 10 round 1: loss_train=0.4185, acc_train=0.9286, loss_test=0.3862, acc_test=0.9888\n",
      "poison_percent 10 round 2: loss_train=0.3710, acc_train=0.9286, loss_test=0.3166, acc_test=0.9944\n",
      "poison_percent 10 round 3: loss_train=0.3512, acc_train=0.9107, loss_test=0.2755, acc_test=0.9949\n",
      "poison_percent 10 round 4: loss_train=0.3593, acc_train=0.8839, loss_test=0.2491, acc_test=0.9949\n",
      "poison_percent 10 round 5: loss_train=0.3339, acc_train=0.8750, loss_test=0.2312, acc_test=0.9949\n",
      "poison_percent 10 round 6: loss_train=0.3257, acc_train=0.8839, loss_test=0.2174, acc_test=0.9949\n",
      "poison_percent 10 round 7: loss_train=0.3927, acc_train=0.8839, loss_test=0.2066, acc_test=0.9954\n",
      "poison_percent 10 round 8: loss_train=0.3746, acc_train=0.8750, loss_test=0.1979, acc_test=0.9949\n",
      "poison_percent 10 round 9: loss_train=0.4352, acc_train=0.8750, loss_test=0.1903, acc_test=0.9949\n",
      "poison_percent 10 round 10: loss_train=0.3513, acc_train=0.8839, loss_test=0.1834, acc_test=0.9949\n",
      "poison_percent 10 round 11: loss_train=0.4225, acc_train=0.8482, loss_test=0.1774, acc_test=0.9944\n",
      "poison_percent 10 round 12: loss_train=0.4310, acc_train=0.8571, loss_test=0.1716, acc_test=0.9944\n",
      "poison_percent 10 round 13: loss_train=0.5463, acc_train=0.8750, loss_test=0.1661, acc_test=0.9949\n",
      "poison_percent 10 round 14: loss_train=0.4818, acc_train=0.8661, loss_test=0.1610, acc_test=0.9949\n",
      "poison_percent 10 round 15: loss_train=0.4555, acc_train=0.8571, loss_test=0.1564, acc_test=0.9949\n",
      "poison_percent 10 round 16: loss_train=0.4995, acc_train=0.8929, loss_test=0.1518, acc_test=0.9949\n",
      "poison_percent 10 round 17: loss_train=0.4573, acc_train=0.8839, loss_test=0.1476, acc_test=0.9944\n",
      "poison_percent 10 round 18: loss_train=0.5202, acc_train=0.8839, loss_test=0.1433, acc_test=0.9944\n",
      "poison_percent 10 round 19: loss_train=0.5037, acc_train=0.8929, loss_test=0.1390, acc_test=0.9944\n",
      "Training log saved to ./results\\FL_MODEL_N1L2_BATCH_SIZE1\\mnist_binary_random_data\\poisoned_10percent\\poisoned_10percent.csv\n",
      "poison_percent 20 round 0: loss_train=0.3953, acc_train=0.9520, loss_test=0.4601, acc_test=0.9561\n",
      "poison_percent 20 round 1: loss_train=0.3334, acc_train=0.9040, loss_test=0.3156, acc_test=0.9939\n",
      "poison_percent 20 round 2: loss_train=0.3430, acc_train=0.9040, loss_test=0.2503, acc_test=0.9959\n",
      "poison_percent 20 round 3: loss_train=0.3522, acc_train=0.8800, loss_test=0.2195, acc_test=0.9964\n",
      "poison_percent 20 round 4: loss_train=0.3305, acc_train=0.8640, loss_test=0.2008, acc_test=0.9964\n",
      "poison_percent 20 round 5: loss_train=0.3693, acc_train=0.8400, loss_test=0.1874, acc_test=0.9964\n",
      "poison_percent 20 round 6: loss_train=0.3848, acc_train=0.8000, loss_test=0.1779, acc_test=0.9969\n",
      "poison_percent 20 round 7: loss_train=0.4402, acc_train=0.8000, loss_test=0.1704, acc_test=0.9969\n",
      "poison_percent 20 round 8: loss_train=0.4831, acc_train=0.8000, loss_test=0.1641, acc_test=0.9969\n",
      "poison_percent 20 round 9: loss_train=0.4678, acc_train=0.8000, loss_test=0.1587, acc_test=0.9969\n",
      "poison_percent 20 round 10: loss_train=0.4659, acc_train=0.7920, loss_test=0.1537, acc_test=0.9969\n",
      "poison_percent 20 round 11: loss_train=0.5787, acc_train=0.8000, loss_test=0.1492, acc_test=0.9969\n",
      "poison_percent 20 round 12: loss_train=0.5980, acc_train=0.8000, loss_test=0.1449, acc_test=0.9969\n",
      "poison_percent 20 round 13: loss_train=0.5969, acc_train=0.8000, loss_test=0.1409, acc_test=0.9969\n",
      "poison_percent 20 round 14: loss_train=0.5925, acc_train=0.8080, loss_test=0.1372, acc_test=0.9974\n",
      "poison_percent 20 round 15: loss_train=0.7502, acc_train=0.7920, loss_test=0.1335, acc_test=0.9974\n",
      "poison_percent 20 round 16: loss_train=0.7125, acc_train=0.8000, loss_test=0.1300, acc_test=0.9974\n",
      "poison_percent 20 round 17: loss_train=0.6814, acc_train=0.8000, loss_test=0.1267, acc_test=0.9974\n",
      "poison_percent 20 round 18: loss_train=0.5721, acc_train=0.8000, loss_test=0.1235, acc_test=0.9974\n",
      "poison_percent 20 round 19: loss_train=0.8389, acc_train=0.7920, loss_test=0.1203, acc_test=0.9974\n",
      "Training log saved to ./results\\FL_MODEL_N1L2_BATCH_SIZE1\\mnist_binary_random_data\\poisoned_20percent\\poisoned_20percent.csv\n",
      "poison_percent 30 round 0: loss_train=0.4019, acc_train=0.8881, loss_test=0.4031, acc_test=0.9852\n",
      "poison_percent 30 round 1: loss_train=0.3571, acc_train=0.8601, loss_test=0.3121, acc_test=0.9939\n",
      "poison_percent 30 round 2: loss_train=0.3648, acc_train=0.8741, loss_test=0.2629, acc_test=0.9959\n",
      "poison_percent 30 round 3: loss_train=0.3953, acc_train=0.8322, loss_test=0.2384, acc_test=0.9954\n",
      "poison_percent 30 round 4: loss_train=0.3742, acc_train=0.8392, loss_test=0.2203, acc_test=0.9959\n",
      "poison_percent 30 round 5: loss_train=0.3725, acc_train=0.8671, loss_test=0.2053, acc_test=0.9964\n",
      "poison_percent 30 round 6: loss_train=0.4112, acc_train=0.8252, loss_test=0.1935, acc_test=0.9964\n",
      "poison_percent 30 round 7: loss_train=0.4380, acc_train=0.7692, loss_test=0.1838, acc_test=0.9980\n",
      "poison_percent 30 round 8: loss_train=0.4522, acc_train=0.7622, loss_test=0.1759, acc_test=0.9980\n",
      "poison_percent 30 round 9: loss_train=0.4686, acc_train=0.7343, loss_test=0.1695, acc_test=0.9980\n",
      "poison_percent 30 round 10: loss_train=0.4575, acc_train=0.7343, loss_test=0.1636, acc_test=0.9980\n",
      "poison_percent 30 round 11: loss_train=0.4914, acc_train=0.7203, loss_test=0.1587, acc_test=0.9980\n",
      "poison_percent 30 round 12: loss_train=0.4868, acc_train=0.7273, loss_test=0.1538, acc_test=0.9980\n",
      "poison_percent 30 round 13: loss_train=0.4958, acc_train=0.7203, loss_test=0.1496, acc_test=0.9980\n",
      "poison_percent 30 round 14: loss_train=0.4910, acc_train=0.7483, loss_test=0.1457, acc_test=0.9980\n",
      "poison_percent 30 round 15: loss_train=0.5108, acc_train=0.7413, loss_test=0.1418, acc_test=0.9980\n",
      "poison_percent 30 round 16: loss_train=0.5790, acc_train=0.7063, loss_test=0.1383, acc_test=0.9980\n",
      "poison_percent 30 round 17: loss_train=0.5758, acc_train=0.7203, loss_test=0.1344, acc_test=0.9980\n",
      "poison_percent 30 round 18: loss_train=0.5767, acc_train=0.7203, loss_test=0.1311, acc_test=0.9980\n",
      "poison_percent 30 round 19: loss_train=0.5750, acc_train=0.7133, loss_test=0.1280, acc_test=0.9980\n",
      "Training log saved to ./results\\FL_MODEL_N1L2_BATCH_SIZE1\\mnist_binary_random_data\\poisoned_30percent\\poisoned_30percent.csv\n",
      "poison_percent 40 round 0: loss_train=0.6846, acc_train=0.4731, loss_test=0.6880, acc_test=0.5000\n",
      "poison_percent 40 round 1: loss_train=0.6685, acc_train=0.4731, loss_test=0.6715, acc_test=0.5000\n",
      "poison_percent 40 round 2: loss_train=0.6446, acc_train=0.4850, loss_test=0.6546, acc_test=0.5000\n",
      "poison_percent 40 round 3: loss_train=0.6442, acc_train=0.4671, loss_test=0.6371, acc_test=0.5000\n",
      "poison_percent 40 round 4: loss_train=0.6074, acc_train=0.5150, loss_test=0.6180, acc_test=0.5000\n",
      "poison_percent 40 round 5: loss_train=0.5944, acc_train=0.5030, loss_test=0.5979, acc_test=0.5000\n",
      "poison_percent 40 round 6: loss_train=0.5987, acc_train=0.4671, loss_test=0.5774, acc_test=0.5000\n",
      "poison_percent 40 round 7: loss_train=0.5852, acc_train=0.4970, loss_test=0.5575, acc_test=0.5000\n",
      "poison_percent 40 round 8: loss_train=0.5643, acc_train=0.5689, loss_test=0.5384, acc_test=0.5000\n",
      "poison_percent 40 round 9: loss_train=0.5761, acc_train=0.5030, loss_test=0.5199, acc_test=0.5000\n",
      "poison_percent 40 round 10: loss_train=0.5766, acc_train=0.5329, loss_test=0.5021, acc_test=0.5000\n",
      "poison_percent 40 round 11: loss_train=0.5632, acc_train=0.5509, loss_test=0.4854, acc_test=0.5000\n",
      "poison_percent 40 round 12: loss_train=0.5891, acc_train=0.7425, loss_test=0.4695, acc_test=0.5000\n",
      "poison_percent 40 round 13: loss_train=0.5989, acc_train=0.5449, loss_test=0.4546, acc_test=0.9862\n",
      "poison_percent 40 round 14: loss_train=0.6052, acc_train=0.5269, loss_test=0.4405, acc_test=0.9883\n",
      "poison_percent 40 round 15: loss_train=0.5686, acc_train=0.5808, loss_test=0.4273, acc_test=0.9888\n",
      "poison_percent 40 round 16: loss_train=0.6265, acc_train=0.5569, loss_test=0.4152, acc_test=0.9913\n",
      "poison_percent 40 round 17: loss_train=0.6262, acc_train=0.5749, loss_test=0.4039, acc_test=0.9923\n",
      "poison_percent 40 round 18: loss_train=0.6361, acc_train=0.5749, loss_test=0.3932, acc_test=0.9934\n",
      "poison_percent 40 round 19: loss_train=0.6633, acc_train=0.5928, loss_test=0.3831, acc_test=0.9944\n",
      "Training log saved to ./results\\FL_MODEL_N1L2_BATCH_SIZE1\\mnist_binary_random_data\\poisoned_40percent\\poisoned_40percent.csv\n",
      "poison_percent 50 round 0: loss_train=0.4707, acc_train=0.8100, loss_test=0.5780, acc_test=0.8194\n",
      "poison_percent 50 round 1: loss_train=0.4045, acc_train=0.9050, loss_test=0.5480, acc_test=0.9199\n",
      "poison_percent 50 round 2: loss_train=0.4019, acc_train=0.9050, loss_test=0.5384, acc_test=0.9327\n",
      "poison_percent 50 round 3: loss_train=0.3773, acc_train=0.9600, loss_test=0.5335, acc_test=0.9383\n",
      "poison_percent 50 round 4: loss_train=0.3859, acc_train=0.9400, loss_test=0.5286, acc_test=0.9429\n",
      "poison_percent 50 round 5: loss_train=0.3767, acc_train=0.9400, loss_test=0.5239, acc_test=0.9474\n",
      "poison_percent 50 round 6: loss_train=0.3848, acc_train=0.9450, loss_test=0.5217, acc_test=0.9480\n",
      "poison_percent 50 round 7: loss_train=0.3693, acc_train=0.9200, loss_test=0.5199, acc_test=0.9464\n",
      "poison_percent 50 round 8: loss_train=0.3745, acc_train=0.9350, loss_test=0.5167, acc_test=0.9464\n",
      "poison_percent 50 round 9: loss_train=0.3812, acc_train=0.9400, loss_test=0.5144, acc_test=0.9459\n",
      "poison_percent 50 round 10: loss_train=0.3740, acc_train=0.9150, loss_test=0.5107, acc_test=0.9469\n",
      "poison_percent 50 round 11: loss_train=0.3880, acc_train=0.9150, loss_test=0.5096, acc_test=0.9469\n",
      "poison_percent 50 round 12: loss_train=0.3738, acc_train=0.9050, loss_test=0.5078, acc_test=0.9444\n",
      "poison_percent 50 round 13: loss_train=0.3821, acc_train=0.9300, loss_test=0.5077, acc_test=0.9434\n",
      "poison_percent 50 round 14: loss_train=0.3896, acc_train=0.9400, loss_test=0.5068, acc_test=0.9429\n",
      "poison_percent 50 round 15: loss_train=0.3800, acc_train=0.9150, loss_test=0.5065, acc_test=0.9418\n",
      "poison_percent 50 round 16: loss_train=0.3569, acc_train=0.9550, loss_test=0.5060, acc_test=0.9403\n",
      "poison_percent 50 round 17: loss_train=0.3797, acc_train=0.9300, loss_test=0.5063, acc_test=0.9372\n",
      "poison_percent 50 round 18: loss_train=0.3447, acc_train=0.9450, loss_test=0.5051, acc_test=0.9352\n",
      "poison_percent 50 round 19: loss_train=0.3576, acc_train=0.9250, loss_test=0.5041, acc_test=0.9321\n",
      "Training log saved to ./results\\FL_MODEL_N1L2_BATCH_SIZE1\\mnist_binary_random_data\\poisoned_50percent\\poisoned_50percent.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BATCH_SIZE_list = []\n",
    "temp_bs = BATCH_SIZE\n",
    "while temp_bs >= 1:\n",
    "    BATCH_SIZE_list.append(temp_bs)\n",
    "    temp_bs = temp_bs // 2\n",
    "\n",
    "for experiment_bs in BATCH_SIZE_list:\n",
    "\n",
    "    name_save_path = f\"FL_MODEL_N1L2_BATCH_SIZE{experiment_bs}\"\n",
    "    mode = \"mnist_binary_random_data\"\n",
    "    for i_poisoned in poison_n_list:\n",
    "        percent_poisoned = int((i_poisoned / (i_poisoned + N_HONEST)) * 100)\n",
    "\n",
    "        # create directory\n",
    "        NAME_SAVE_update_PATH = f\"poisoned_{percent_poisoned}percent\"\n",
    "        save_path = os.path.join(RESULT_PATH,name_save_path,mode,NAME_SAVE_update_PATH)\n",
    "        # Remove existing directory if it exists\n",
    "        if os.path.exists(save_path):\n",
    "            shutil.rmtree(save_path)\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        save_all_path = os.path.join(RESULT_PATH,name_save_path,mode,'all')\n",
    "        os.makedirs(save_all_path, exist_ok=True)\n",
    "        \n",
    "        # Load data\n",
    "        X_test, y_test = load_mnist_binary_test_data_flat(TEST_PATH, img_size=IMG_SIZE)\n",
    "        if X_test.shape[0] == 0:\n",
    "            raise ValueError(\"No valid test images found in the test directory!\")\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "        global_model = MNISTNet().to(device)\n",
    "        torch.save(global_model, os.path.join(save_path,'model_init.pt'))\n",
    "        global_weights = global_model.state_dict()\n",
    "\n",
    "        records = []\n",
    "\n",
    "        X_train_tensor = {}\n",
    "        y_train_tensor = {}\n",
    "        for i in range(N_HONEST):\n",
    "            X_c, y_c = get_client_data(DATA_PATH, \"honest\", i, img_size=IMG_SIZE)\n",
    "            if len(X_c) == 0:\n",
    "                continue\n",
    "            X_c_tensor = torch.tensor(X_c, dtype=torch.float32).to(device)\n",
    "            y_c_tensor = torch.tensor(y_c, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "            X_train_tensor[f\"honest_{i}\"] = X_c_tensor\n",
    "            y_train_tensor[f\"honest_{i}\"] = y_c_tensor\n",
    "        for i in range(i_poisoned):\n",
    "            X_c, y_c = get_client_data(DATA_PATH, \"poison\", i, img_size=IMG_SIZE)\n",
    "            if len(X_c) == 0:\n",
    "                continue\n",
    "            X_c_tensor = torch.tensor(X_c, dtype=torch.float32).to(device)\n",
    "            y_c_tensor = torch.tensor(y_c, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "            X_train_tensor[f\"poison_{i}\"] = X_c_tensor\n",
    "            y_train_tensor[f\"poison_{i}\"] = y_c_tensor\n",
    "\n",
    "        # Training loop\n",
    "        for round in range(ROUNDS):\n",
    "            # Prepare arguments for honest clients\n",
    "            \n",
    "            #randomize the training data\n",
    "            for i in range(N_HONEST):\n",
    "                perm = torch.randperm(X_train_tensor[f\"honest_{i}\"].size(0))\n",
    "                X_train_tensor[f\"honest_{i}\"] = X_train_tensor[f\"honest_{i}\"][perm]\n",
    "                y_train_tensor[f\"honest_{i}\"] = y_train_tensor[f\"honest_{i}\"][perm]\n",
    "\n",
    "            honest_args = [\n",
    "                (\n",
    "                    X_train_tensor[f\"honest_{i}\"],\n",
    "                    y_train_tensor[f\"honest_{i}\"],\n",
    "                    global_weights,\n",
    "                    LEARNING_RATE,\n",
    "                    LOCAL_EPOCHS,\n",
    "                    experiment_bs,\n",
    "                    device\n",
    "                )\n",
    "                for i in range(N_HONEST)\n",
    "            ]\n",
    "\n",
    "            # Prepare arguments for poisoned clients\n",
    "            \n",
    "            #randomize the training data\n",
    "            for i in range(i_poisoned):\n",
    "                perm = torch.randperm(X_train_tensor[f\"poison_{i}\"].size(0))\n",
    "                X_train_tensor[f\"poison_{i}\"] = X_train_tensor[f\"poison_{i}\"][perm]\n",
    "                y_train_tensor[f\"poison_{i}\"] = y_train_tensor[f\"poison_{i}\"][perm]\n",
    "\n",
    "            poison_args = [\n",
    "                (\n",
    "                    X_train_tensor[f\"poison_{i}\"],\n",
    "                    y_train_tensor[f\"poison_{i}\"],\n",
    "                    global_weights,\n",
    "                    LEARNING_RATE,\n",
    "                    LOCAL_EPOCHS,\n",
    "                    experiment_bs,\n",
    "                    device\n",
    "                )\n",
    "                for i in range(i_poisoned)\n",
    "            ]\n",
    "\n",
    "            # Run in parallel\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "                honest_results = list(executor.map(train_local_worker, honest_args))\n",
    "                poison_results = list(executor.map(train_local_worker, poison_args))\n",
    "\n",
    "            local_weights = []\n",
    "            local_sizes = []\n",
    "            local_y = []\n",
    "            local_outputs = []\n",
    "            local_preds = []\n",
    "            for l_w, l_sz, l_y, l_out, l_pred in honest_results + poison_results:\n",
    "                local_weights.append(l_w)\n",
    "                local_sizes.append(l_sz)\n",
    "                local_y.extend(l_y)\n",
    "                local_outputs.extend(l_out)\n",
    "                local_preds.extend(l_pred)\n",
    "            loss_train = binary_cross_entropy(torch.stack(local_outputs), torch.stack(local_y))\n",
    "            acc_train = (torch.stack(local_preds) == torch.stack(local_y)).float().mean().item()\n",
    "\n",
    "\n",
    "            # Federated averaging (weighted by client data size)\n",
    "            new_weights = {}\n",
    "            for key in global_weights.keys():\n",
    "                new_weights[key] = sum([w[key]*sz for w, sz in zip(local_weights, local_sizes)]) / sum(local_sizes)\n",
    "            global_weights = new_weights\n",
    "            global_model.load_state_dict(global_weights)\n",
    "\n",
    "            # Evaluate\n",
    "            global_model.eval()\n",
    "            with torch.no_grad():\n",
    "                outputs = global_model(X_test_tensor)\n",
    "                preds = (outputs > 0.5).float()\n",
    "                loss_test = binary_cross_entropy(outputs, y_test_tensor)\n",
    "                acc_test = (preds == y_test_tensor).float().mean().item()\n",
    "            records.append({'poison_percent': percent_poisoned, 'round': round, \n",
    "                            'loss_train': loss_train.item(), 'acc_train': acc_train, \n",
    "                            'loss_test': loss_test.item(), 'acc_test': acc_test})\n",
    "            report_txt = f\"poison_percent {percent_poisoned} \"\n",
    "            report_txt += f\"round {round}: \"\n",
    "            report_txt += f\"loss_train={loss_train.item():.4f}, \"\n",
    "            report_txt += f\"acc_train={acc_train:.4f}, \"\n",
    "            report_txt += f\"loss_test={loss_test.item():.4f}, \"\n",
    "            report_txt += f\"acc_test={acc_test:.4f}\"\n",
    "            print(report_txt)\n",
    "\n",
    "        torch.save(global_model, os.path.join(save_path,'model_init.pt'))\n",
    "\n",
    "        # Save training log\n",
    "        df = pd.DataFrame(records)\n",
    "        save_name_path = os.path.join(save_path, f'{NAME_SAVE_update_PATH}.csv')\n",
    "        df.to_csv(save_name_path, index=False)\n",
    "        print(f\"Training log saved to {save_name_path}\")\n",
    "\n",
    "        # Plot loss and accuracy\n",
    "        plt.figure(figsize=(10,4))\n",
    "\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(df['round'], df['loss_test'], marker='o')\n",
    "        plt.title('Test Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.grid(True)\n",
    "        plt.ylim(0, 1.1)\n",
    "        # plt.legend()\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(df['round'], df['acc_test'], marker='o')\n",
    "        plt.title('Test Accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.grid(True)\n",
    "        plt.ylim(0, 1.1)\n",
    "        # plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        save_name_path = os.path.join(save_path, f'loss_accuracy.jpg')\n",
    "        plt.savefig(save_name_path)\n",
    "\n",
    "        save_name_path = os.path.join(save_all_path, f'{NAME_SAVE_update_PATH}_latest.jpg')\n",
    "        plt.savefig(save_name_path)\n",
    "        plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

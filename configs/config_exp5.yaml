# EXP 5: Defense Mechanism Comparison
# IEEE Publication-Ready Configuration
# Goal: Benchmark intrinsic (model width) vs extrinsic (robust aggregation) defenses
# Statistical Rigor: 5 random seeds, controlled comparison
# Expected Runtime: ~40-60 hours (180 experiments: 2 datasets × 2 aggregators × 3 poison levels × 5 seeds)

defaults:
  project_name: "FL_EXP5_Defense_Benchmark"
  output_dir: "./results_exp5_{dataset}"
  load_to_memory: true
  
  # Federated Learning Configuration
  num_clients: 10
  fraction_fit: 1.0
  global_rounds: 3000                # Increased for convergence
  local_epochs: 5
  batch_size: 128
  num_parallel_workers: 1
  
  # Optimization (IEEE standard settings)
  optimizer: "sgd"
  lr: 0.02
  momentum: 0.9
  weight_decay: 5e-4
  
  # Model Architecture
  depth: 4
  
  # Validation & Early Stopping
  validation_split: 0.1
  early_stopping_patience: 10        # Increased for IEEE standards
  min_delta: 0.0001

  # Poisoning Attack Configuration
  poison_type: "label_flip"
  target_class: 0
  poison_label: 1
  poison_ratio: 0.0                  # Varied in combinations
  alpha: 100.0
  data_ordering: "shuffle"
  aggregator: "fedavg"               # Varied in combinations

# Defense Comparison: FedAvg vs Byzantine-Robust Aggregation
exp5_defense_comparison:
  combinations:
    - seed: [42, 101, 2024, 3141, 9876]  # Statistical significance
    - model_type: ["lr", "cnn"]                     # Model comparison
    - dataset: ["mnist", "cifar10"]
    - aggregator: ["fedavg", "median"]         # Baseline vs robust aggregation
    - width_factor: [4]                        # Fixed width for controlled comparison (CNN only)
    - poison_ratio: [0.0, 0.3, 0.5]           # Clean, moderate, severe

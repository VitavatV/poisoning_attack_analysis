# EXP 2: Batch Size and Data Ordering Analysis
# IEEE Publication-Ready Configuration  
# Goal: Investigate mechanism of robustness through batch size and data ordering
# Statistical Rigor: 5 random seeds, factorial design
# Expected Runtime: ~100-150 hours (540 experiments: 2 datasets × 3 batch sizes × 3 orderings × 3 poison levels × 5 seeds)

defaults:
  project_name: "FL_EXP2_Mechanism_Analysis"
  output_dir: "./results_exp2_{dataset}"
  load_to_memory: true
  
  # Federated Learning Configuration
  num_clients: 10
  fraction_fit: 1.0
  global_rounds: 3000                # Increased for convergence
  local_epochs: 5
  batch_size: 128                    # Default (varied in combinations)
  num_parallel_workers: 1
  
  # Optimization (IEEE standard settings)
  optimizer: "sgd"
  lr: 0.01
  momentum: 0.9
  weight_decay: 5e-4
  
  # Model Architecture
  depth: 4
  
  # Validation & Early Stopping
  validation_split: 0.1
  early_stopping_patience: 20        # Increased for IEEE standards
  min_delta: 0.0001

  # Poisoning Attack Configuration
  poison_type: "label_flip"
  target_class: 0
  poison_label: 1
  poison_ratio: 0.0                  # Varied in combinations
  alpha: 100.0
  data_ordering: "shuffle"           # Varied in combinations
  aggregator: "fedavg"

# Factorial Design: Batch Size × Data Ordering × Poison Level
exp2_mechanism_analysis:
  combinations:
    - seed: [42, 101, 2024, 3141, 9876]  # Statistical significance
    - model_type: ["cnn", "lr"]                     # Model comparison
    - dataset: ["mnist", "cifar10"]
    - batch_size: [128, 32, 8]                 # Large, medium, small batches
    - data_ordering: ["shuffle", "bad_good", "good_bad"]  # Different ordering strategies
    - width_factor: [4]                        # Fixed width for controlled comparison (CNN only)
    - poison_ratio: [0.0, 0.3, 0.5]           # Clean, moderate, severe

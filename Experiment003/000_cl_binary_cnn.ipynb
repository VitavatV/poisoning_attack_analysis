{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe2f4522",
   "metadata": {},
   "source": [
    "# 1.Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad45b87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2207c249db0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8df274b",
   "metadata": {},
   "source": [
    "# 2.Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "889281eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_binary_data(data_dir, honest_range=100, poison_range=100, img_size=28,select='Honest+Poisoned'):\n",
    "    X = []\n",
    "    y = []\n",
    "    def load_honest(X, y):\n",
    "        for i in range(honest_range):\n",
    "            folder = os.path.join(data_dir, f\"honest_{i}\")\n",
    "            if not os.path.exists(folder):\n",
    "                continue\n",
    "            for label in os.listdir(folder):\n",
    "                label_folder = os.path.join(folder, label)\n",
    "                if not os.path.isdir(label_folder):\n",
    "                    continue\n",
    "                for fname in os.listdir(label_folder):\n",
    "                    if fname.endswith('.png') or fname.endswith('.jpg'):\n",
    "                        img = Image.open(os.path.join(label_folder, fname)).convert('L').resize((img_size, img_size))\n",
    "                        X.append(np.array(img).flatten() / 255.0)\n",
    "                        y.append(label)\n",
    "        return X, y\n",
    "    def load_poisoned(X, y):\n",
    "        for i in range(poison_range):\n",
    "            folder = os.path.join(data_dir, f\"poison_{i}\")\n",
    "            if not os.path.exists(folder):\n",
    "                continue\n",
    "            for label in os.listdir(folder):\n",
    "                label_folder = os.path.join(folder, label)\n",
    "                if not os.path.isdir(label_folder):\n",
    "                    continue\n",
    "                for fname in os.listdir(label_folder):\n",
    "                    if fname.endswith('.png') or fname.endswith('.jpg'):\n",
    "                        img = Image.open(os.path.join(label_folder, fname)).convert('L').resize((img_size, img_size))\n",
    "                        X.append(np.array(img).flatten() / 255.0)\n",
    "                        y.append(label)\n",
    "        return X, y\n",
    "    \n",
    "    if select == 'Honest+Poisoned':\n",
    "        X, y = load_honest(X, y)\n",
    "        X, y = load_poisoned(X, y)\n",
    "    elif select == 'Poisoned+Honest':\n",
    "        X, y = load_poisoned(X, y)\n",
    "        X, y = load_honest(X, y)\n",
    "    elif select == 'Honest':\n",
    "        X, y = load_honest(X, y)\n",
    "    elif select == 'Poisoned':\n",
    "        X, y = load_poisoned(X, y)\n",
    "\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    y = np.array(y, dtype=np.float32)\n",
    "    return X, y\n",
    "\n",
    "def load_mnist_binary_test_data(test_dir, img_size=28):\n",
    "    X = []\n",
    "    y = []\n",
    "    if not os.path.exists(test_dir):\n",
    "        return X, y\n",
    "    for label in ['0', '1']:\n",
    "        label_folder = os.path.join(test_dir, label)\n",
    "        if not os.path.isdir(label_folder):\n",
    "            continue\n",
    "        for fname in os.listdir(label_folder):\n",
    "            if fname.endswith('.png') or fname.endswith('.jpg'):\n",
    "                img = Image.open(os.path.join(label_folder, fname)).convert('L').resize((img_size, img_size))\n",
    "                X.append(np.array(img).flatten() / 255.0)\n",
    "                y.append(label)\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    y = np.array(y, dtype=np.float32)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473a4c3e",
   "metadata": {},
   "source": [
    "# 3.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6fcd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 1, kernel_size=3, padding=1) # 28x28\n",
    "        self.pool = nn.MaxPool2d(2, 2) # 14x14\n",
    "        self.fc1 = nn.Linear(1 * 14 * 14, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "# save state_dict + metadata (safe, portable)\n",
    "def save_model(model, img_size, n_classes, learning_rate, experiment_bs, file_path):\n",
    "\n",
    "    state = {\n",
    "        \"model_state_dict\": model.state_dict(),                     # CPU/GPU tensors okay\n",
    "        \"arch\": \"MNISTNet\",\n",
    "        \"img_size\": img_size,\n",
    "        \"num_classes\": n_classes,\n",
    "        \"training_args\": {\"lr\": learning_rate, \"batch_size\": experiment_bs}\n",
    "    }\n",
    "    # ensure weights are on CPU to avoid GPU-only pickle issues\n",
    "    state[\"model_state_dict\"] = {k: v.cpu() for k, v in state[\"model_state_dict\"].items()}\n",
    "    torch.save(state, file_path)\n",
    "    \n",
    "def load_model(file_path, device):\n",
    "\n",
    "    checkpoint = torch.load(file_path, map_location=device)\n",
    "    model = MNISTNet().to(device)              # must have MNISTNet class defined/importable\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096e6300",
   "metadata": {},
   "source": [
    "# 4.Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd29671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(pred, target):\n",
    "    eps = 1e-7\n",
    "    pred = torch.clamp(pred, eps, 1 - eps)\n",
    "    return -(target * torch.log(pred) + (1 - target) * torch.log(1 - pred)).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f5df39",
   "metadata": {},
   "source": [
    "# 5.Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66763e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_HONEST = 100\n",
    "N_POISONED = 100\n",
    "IMG_SIZE = 28\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "N_CLASSES = 2\n",
    "\n",
    "# Set device\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "DATA_PATH = \"./data/mnist_binary_poison/train\"\n",
    "TEST_PATH = \"./data/mnist_binary_poison/test\"\n",
    "\n",
    "RESULT_PATH = \"./results\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6888dfd7",
   "metadata": {},
   "source": [
    "# 6.Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "886592d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding poison n: 0 for percent: 0\n",
      "Adding poison n: 12 for percent: 10\n",
      "Adding poison n: 25 for percent: 20\n",
      "Adding poison n: 43 for percent: 30\n",
      "Adding poison n: 67 for percent: 40\n",
      "Adding poison n: 100 for percent: 50\n",
      "Poison n list: [0, 12, 25, 43, 67, 100]\n"
     ]
    }
   ],
   "source": [
    "poison_percent = [0, 10, 20, 30, 40, 50]\n",
    "poison_n_list = []\n",
    "for p in range(0,N_POISONED+1):\n",
    "    percent = int((p / (p+N_HONEST)) * 100)\n",
    "    if percent in poison_percent:\n",
    "        poison_percent.remove(percent)\n",
    "        print(f\"Adding poison n: {p} for percent: {percent}\")\n",
    "        poison_n_list.append(p)\n",
    "print(\"Poison n list:\", poison_n_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "438c0487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poison_percent 0 epoch 0: loss_train=0.0133, acc_train=1.0000, loss_test=0.0025, acc_test=0.9995\n",
      "poison_percent 0 epoch 1: loss_train=0.0019, acc_train=1.0000, loss_test=0.0020, acc_test=0.9990\n",
      "poison_percent 0 epoch 2: loss_train=0.0000, acc_train=1.0000, loss_test=0.0018, acc_test=0.9990\n",
      "poison_percent 0 epoch 3: loss_train=0.0000, acc_train=1.0000, loss_test=0.0019, acc_test=0.9990\n",
      "poison_percent 0 epoch 4: loss_train=0.0000, acc_train=1.0000, loss_test=0.0013, acc_test=0.9995\n",
      "poison_percent 0 epoch 5: loss_train=0.0000, acc_train=1.0000, loss_test=0.0011, acc_test=0.9995\n",
      "poison_percent 0 epoch 6: loss_train=0.0001, acc_train=1.0000, loss_test=0.0011, acc_test=1.0000\n",
      "poison_percent 0 epoch 7: loss_train=0.0000, acc_train=1.0000, loss_test=0.0014, acc_test=0.9995\n",
      "poison_percent 0 epoch 8: loss_train=0.0000, acc_train=1.0000, loss_test=0.0029, acc_test=0.9995\n",
      "poison_percent 0 epoch 9: loss_train=0.0000, acc_train=1.0000, loss_test=0.0059, acc_test=0.9980\n",
      "poison_percent 0 epoch 10: loss_train=0.0000, acc_train=1.0000, loss_test=0.0021, acc_test=0.9990\n",
      "poison_percent 0 epoch 11: loss_train=0.0000, acc_train=1.0000, loss_test=0.0018, acc_test=0.9990\n",
      "poison_percent 0 epoch 12: loss_train=0.0000, acc_train=1.0000, loss_test=0.0029, acc_test=0.9990\n",
      "poison_percent 0 epoch 13: loss_train=0.0000, acc_train=1.0000, loss_test=0.0022, acc_test=0.9990\n",
      "poison_percent 0 epoch 14: loss_train=0.0000, acc_train=1.0000, loss_test=0.0032, acc_test=0.9990\n",
      "poison_percent 0 epoch 15: loss_train=0.0000, acc_train=1.0000, loss_test=0.0025, acc_test=0.9995\n",
      "poison_percent 0 epoch 16: loss_train=0.0000, acc_train=1.0000, loss_test=0.0023, acc_test=0.9995\n",
      "poison_percent 0 epoch 17: loss_train=0.0149, acc_train=1.0000, loss_test=0.0020, acc_test=0.9995\n",
      "poison_percent 0 epoch 18: loss_train=0.0000, acc_train=1.0000, loss_test=0.0019, acc_test=0.9990\n",
      "poison_percent 0 epoch 19: loss_train=0.0000, acc_train=1.0000, loss_test=0.0023, acc_test=0.9995\n",
      "poison_percent 0 epoch 20: loss_train=0.0000, acc_train=1.0000, loss_test=0.0020, acc_test=0.9995\n",
      "poison_percent 0 epoch 21: loss_train=0.0000, acc_train=1.0000, loss_test=0.0021, acc_test=0.9995\n",
      "poison_percent 0 epoch 22: loss_train=0.0000, acc_train=1.0000, loss_test=0.0033, acc_test=0.9990\n",
      "poison_percent 0 epoch 23: loss_train=0.0000, acc_train=1.0000, loss_test=0.0029, acc_test=0.9985\n",
      "poison_percent 0 epoch 24: loss_train=0.0000, acc_train=1.0000, loss_test=0.0018, acc_test=0.9995\n",
      "poison_percent 0 epoch 25: loss_train=0.0000, acc_train=1.0000, loss_test=0.0007, acc_test=1.0000\n",
      "poison_percent 0 epoch 26: loss_train=0.0000, acc_train=1.0000, loss_test=0.0014, acc_test=0.9990\n",
      "poison_percent 0 epoch 27: loss_train=0.0000, acc_train=1.0000, loss_test=0.0017, acc_test=0.9995\n",
      "poison_percent 0 epoch 28: loss_train=0.0000, acc_train=1.0000, loss_test=0.0022, acc_test=0.9995\n",
      "poison_percent 0 epoch 29: loss_train=0.0000, acc_train=1.0000, loss_test=0.0020, acc_test=0.9995\n",
      "poison_percent 0 epoch 30: loss_train=0.0000, acc_train=1.0000, loss_test=0.0020, acc_test=0.9995\n",
      "poison_percent 0 epoch 31: loss_train=0.0000, acc_train=1.0000, loss_test=0.0030, acc_test=0.9990\n",
      "poison_percent 0 epoch 32: loss_train=0.0000, acc_train=1.0000, loss_test=0.0009, acc_test=1.0000\n",
      "poison_percent 0 epoch 33: loss_train=0.0000, acc_train=1.0000, loss_test=0.0006, acc_test=1.0000\n",
      "poison_percent 0 epoch 34: loss_train=0.0000, acc_train=1.0000, loss_test=0.0009, acc_test=0.9995\n",
      "poison_percent 0 epoch 35: loss_train=0.0000, acc_train=1.0000, loss_test=0.0037, acc_test=0.9990\n",
      "poison_percent 0 epoch 36: loss_train=0.0000, acc_train=1.0000, loss_test=0.0024, acc_test=0.9990\n",
      "poison_percent 0 epoch 37: loss_train=0.0000, acc_train=1.0000, loss_test=0.0042, acc_test=0.9985\n",
      "poison_percent 0 epoch 38: loss_train=0.0000, acc_train=1.0000, loss_test=0.0007, acc_test=0.9995\n",
      "poison_percent 0 epoch 39: loss_train=0.0000, acc_train=1.0000, loss_test=0.0010, acc_test=0.9990\n",
      "poison_percent 0 epoch 40: loss_train=0.0000, acc_train=1.0000, loss_test=0.0040, acc_test=0.9985\n",
      "poison_percent 0 epoch 41: loss_train=0.0000, acc_train=1.0000, loss_test=0.0012, acc_test=0.9995\n",
      "poison_percent 0 epoch 42: loss_train=0.0000, acc_train=1.0000, loss_test=0.0014, acc_test=0.9995\n",
      "poison_percent 0 epoch 43: loss_train=0.0000, acc_train=1.0000, loss_test=0.0020, acc_test=0.9985\n",
      "poison_percent 0 epoch 44: loss_train=0.0000, acc_train=1.0000, loss_test=0.0016, acc_test=0.9995\n",
      "poison_percent 0 epoch 45: loss_train=0.0000, acc_train=1.0000, loss_test=0.0017, acc_test=0.9990\n",
      "poison_percent 0 epoch 46: loss_train=0.0000, acc_train=1.0000, loss_test=0.0068, acc_test=0.9985\n",
      "poison_percent 0 epoch 47: loss_train=0.0000, acc_train=1.0000, loss_test=0.0020, acc_test=0.9985\n",
      "poison_percent 0 epoch 48: loss_train=0.0000, acc_train=1.0000, loss_test=0.0011, acc_test=0.9995\n",
      "poison_percent 0 epoch 49: loss_train=0.0000, acc_train=1.0000, loss_test=0.0017, acc_test=0.9990\n",
      "poison_percent 0 epoch 50: loss_train=0.0000, acc_train=1.0000, loss_test=0.0022, acc_test=0.9985\n",
      "poison_percent 0 epoch 51: loss_train=0.0000, acc_train=1.0000, loss_test=0.0019, acc_test=0.9995\n",
      "poison_percent 0 epoch 52: loss_train=0.0000, acc_train=1.0000, loss_test=0.0019, acc_test=0.9990\n",
      "poison_percent 0 epoch 53: loss_train=0.0000, acc_train=1.0000, loss_test=0.0029, acc_test=0.9985\n",
      "poison_percent 0 epoch 54: loss_train=0.0000, acc_train=1.0000, loss_test=0.0034, acc_test=0.9985\n",
      "poison_percent 0 epoch 55: loss_train=0.0000, acc_train=1.0000, loss_test=0.0025, acc_test=0.9985\n",
      "poison_percent 0 epoch 56: loss_train=0.0000, acc_train=1.0000, loss_test=0.0074, acc_test=0.9985\n",
      "poison_percent 0 epoch 57: loss_train=0.0000, acc_train=1.0000, loss_test=0.0038, acc_test=0.9980\n",
      "poison_percent 0 epoch 58: loss_train=0.0000, acc_train=1.0000, loss_test=0.0021, acc_test=0.9990\n",
      "poison_percent 0 epoch 59: loss_train=0.0000, acc_train=1.0000, loss_test=0.0043, acc_test=0.9990\n",
      "poison_percent 0 epoch 60: loss_train=0.0000, acc_train=1.0000, loss_test=0.0041, acc_test=0.9990\n",
      "poison_percent 0 epoch 61: loss_train=0.0000, acc_train=1.0000, loss_test=0.0086, acc_test=0.9990\n",
      "poison_percent 0 epoch 62: loss_train=0.0000, acc_train=1.0000, loss_test=0.0046, acc_test=0.9985\n",
      "poison_percent 0 epoch 63: loss_train=0.0000, acc_train=1.0000, loss_test=0.0026, acc_test=0.9990\n",
      "poison_percent 0 epoch 64: loss_train=0.0000, acc_train=1.0000, loss_test=0.0027, acc_test=0.9990\n",
      "poison_percent 0 epoch 65: loss_train=0.0000, acc_train=1.0000, loss_test=0.0038, acc_test=0.9990\n",
      "poison_percent 0 epoch 66: loss_train=0.0000, acc_train=1.0000, loss_test=0.0022, acc_test=0.9990\n",
      "poison_percent 0 epoch 67: loss_train=0.0000, acc_train=1.0000, loss_test=0.0026, acc_test=0.9985\n",
      "poison_percent 0 epoch 68: loss_train=0.0000, acc_train=1.0000, loss_test=0.0021, acc_test=0.9995\n",
      "poison_percent 0 epoch 69: loss_train=0.0000, acc_train=1.0000, loss_test=0.0053, acc_test=0.9985\n",
      "poison_percent 0 epoch 70: loss_train=0.0000, acc_train=1.0000, loss_test=0.0027, acc_test=0.9995\n",
      "poison_percent 0 epoch 71: loss_train=0.0000, acc_train=1.0000, loss_test=0.0021, acc_test=0.9995\n",
      "poison_percent 0 epoch 72: loss_train=0.0000, acc_train=1.0000, loss_test=0.0026, acc_test=0.9990\n",
      "poison_percent 0 epoch 73: loss_train=0.0000, acc_train=1.0000, loss_test=0.0156, acc_test=0.9985\n",
      "poison_percent 0 epoch 74: loss_train=0.0000, acc_train=1.0000, loss_test=0.0034, acc_test=0.9985\n",
      "poison_percent 0 epoch 75: loss_train=0.0000, acc_train=1.0000, loss_test=0.0025, acc_test=0.9995\n",
      "poison_percent 0 epoch 76: loss_train=0.0000, acc_train=1.0000, loss_test=0.0036, acc_test=0.9985\n",
      "poison_percent 0 epoch 77: loss_train=0.0000, acc_train=1.0000, loss_test=0.0015, acc_test=0.9995\n",
      "poison_percent 0 epoch 78: loss_train=0.0000, acc_train=1.0000, loss_test=0.0052, acc_test=0.9990\n",
      "poison_percent 0 epoch 79: loss_train=0.0000, acc_train=1.0000, loss_test=0.0035, acc_test=0.9990\n",
      "poison_percent 0 epoch 80: loss_train=0.0000, acc_train=1.0000, loss_test=0.0027, acc_test=0.9995\n",
      "poison_percent 0 epoch 81: loss_train=0.0000, acc_train=1.0000, loss_test=0.0028, acc_test=0.9990\n",
      "poison_percent 0 epoch 82: loss_train=0.0000, acc_train=1.0000, loss_test=0.0040, acc_test=0.9985\n",
      "poison_percent 0 epoch 83: loss_train=0.0000, acc_train=1.0000, loss_test=0.0033, acc_test=0.9990\n",
      "poison_percent 0 epoch 84: loss_train=0.0000, acc_train=1.0000, loss_test=0.0040, acc_test=0.9990\n",
      "poison_percent 0 epoch 85: loss_train=0.0000, acc_train=1.0000, loss_test=0.0031, acc_test=0.9990\n",
      "poison_percent 0 epoch 86: loss_train=0.0000, acc_train=1.0000, loss_test=0.0028, acc_test=0.9995\n",
      "poison_percent 0 epoch 87: loss_train=0.0000, acc_train=1.0000, loss_test=0.0020, acc_test=0.9995\n",
      "poison_percent 0 epoch 88: loss_train=0.0000, acc_train=1.0000, loss_test=0.0014, acc_test=0.9995\n",
      "poison_percent 0 epoch 89: loss_train=0.0000, acc_train=1.0000, loss_test=0.0030, acc_test=0.9990\n",
      "poison_percent 0 epoch 90: loss_train=0.0000, acc_train=1.0000, loss_test=0.0028, acc_test=0.9995\n",
      "poison_percent 0 epoch 91: loss_train=0.0000, acc_train=1.0000, loss_test=0.0027, acc_test=0.9995\n",
      "poison_percent 0 epoch 92: loss_train=0.0000, acc_train=1.0000, loss_test=0.0065, acc_test=0.9990\n",
      "poison_percent 0 epoch 93: loss_train=0.0000, acc_train=1.0000, loss_test=0.0075, acc_test=0.9985\n",
      "poison_percent 0 epoch 94: loss_train=0.0000, acc_train=1.0000, loss_test=0.0085, acc_test=0.9990\n",
      "poison_percent 0 epoch 95: loss_train=0.0000, acc_train=1.0000, loss_test=0.0031, acc_test=0.9995\n",
      "poison_percent 0 epoch 96: loss_train=0.0000, acc_train=1.0000, loss_test=0.0031, acc_test=0.9995\n",
      "poison_percent 0 epoch 97: loss_train=0.0000, acc_train=1.0000, loss_test=0.0032, acc_test=0.9995\n",
      "poison_percent 0 epoch 98: loss_train=0.0000, acc_train=1.0000, loss_test=0.0028, acc_test=0.9990\n",
      "poison_percent 0 epoch 99: loss_train=0.0000, acc_train=1.0000, loss_test=0.0037, acc_test=0.9995\n",
      "Training log saved to ./results\\CL_ModelN1L1_Batchsize1_rev0\\poisoned_0percent\\poisoned_0percent.csv\n",
      "poison_percent 10 epoch 0: loss_train=15.9424, acc_train=0.0000, loss_test=0.0077, acc_test=0.9985\n",
      "poison_percent 10 epoch 1: loss_train=0.0000, acc_train=1.0000, loss_test=0.0051, acc_test=0.9990\n",
      "poison_percent 10 epoch 2: loss_train=0.0000, acc_train=1.0000, loss_test=0.0054, acc_test=0.9990\n",
      "poison_percent 10 epoch 3: loss_train=15.9424, acc_train=0.0000, loss_test=0.0084, acc_test=0.9990\n",
      "poison_percent 10 epoch 4: loss_train=0.0000, acc_train=1.0000, loss_test=0.0088, acc_test=0.9990\n",
      "poison_percent 10 epoch 5: loss_train=0.0000, acc_train=1.0000, loss_test=0.0090, acc_test=0.9990\n",
      "poison_percent 10 epoch 6: loss_train=0.0000, acc_train=1.0000, loss_test=0.0115, acc_test=0.9974\n",
      "poison_percent 10 epoch 7: loss_train=0.0000, acc_train=1.0000, loss_test=0.0068, acc_test=0.9985\n",
      "poison_percent 10 epoch 8: loss_train=0.0000, acc_train=1.0000, loss_test=0.0061, acc_test=0.9985\n",
      "poison_percent 10 epoch 9: loss_train=0.0000, acc_train=1.0000, loss_test=0.0067, acc_test=0.9995\n",
      "poison_percent 10 epoch 10: loss_train=0.0000, acc_train=1.0000, loss_test=0.0081, acc_test=0.9995\n",
      "poison_percent 10 epoch 11: loss_train=0.0000, acc_train=1.0000, loss_test=0.0059, acc_test=0.9995\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     67\u001b[39m preds = (outputs >= \u001b[32m0.5\u001b[39m).float()\n\u001b[32m     68\u001b[39m acc_train = (preds == yb).float().mean().item()\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m loss_train = \u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m optimizer.zero_grad()\n\u001b[32m     71\u001b[39m loss_train.backward()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mbinary_cross_entropy\u001b[39m\u001b[34m(pred, target)\u001b[39m\n\u001b[32m      2\u001b[39m eps = \u001b[32m1e-7\u001b[39m\n\u001b[32m      3\u001b[39m pred = torch.clamp(pred, eps, \u001b[32m1\u001b[39m - eps)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m -(target * torch.log(pred) + (\u001b[32m1\u001b[39m - target) * \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m).mean()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "BATCH_SIZE_list = []\n",
    "temp_bs = BATCH_SIZE\n",
    "while temp_bs >= 1:\n",
    "    BATCH_SIZE_list.append(temp_bs)\n",
    "    temp_bs = temp_bs // 2\n",
    "\n",
    "for rev in range(3):\n",
    "\n",
    "    model = MNISTNet().to(device)\n",
    "    for experiment_bs in BATCH_SIZE_list:\n",
    "\n",
    "        name_save_path = f\"CL_ModelN1L1_Batchsize{experiment_bs}_rev{rev}\"\n",
    "        \n",
    "        for i_poisoned in poison_n_list:\n",
    "            percent_poisoned = int((i_poisoned / (i_poisoned + N_HONEST)) * 100)\n",
    "\n",
    "            # create directory\n",
    "            NAME_SAVE_update_PATH = f\"poisoned_{percent_poisoned}percent\"\n",
    "            save_path = os.path.join(RESULT_PATH,name_save_path,NAME_SAVE_update_PATH)\n",
    "            # Remove existing directory if it exists\n",
    "            if os.path.exists(save_path):\n",
    "                shutil.rmtree(save_path)\n",
    "            if not os.path.exists(save_path):\n",
    "                os.makedirs(save_path)\n",
    "            save_all_path = os.path.join(RESULT_PATH,name_save_path,'all')\n",
    "            os.makedirs(save_all_path, exist_ok=True)\n",
    "            \n",
    "            # Load data\n",
    "            X_train, y_train = load_mnist_binary_data( DATA_PATH, honest_range=N_HONEST, \n",
    "                                                    poison_range=i_poisoned, img_size=IMG_SIZE, \n",
    "                                                    select='Honest+Poisoned')\n",
    "            X_test, y_test = load_mnist_binary_test_data( TEST_PATH, img_size=IMG_SIZE)\n",
    "            # print(f\"Loaded train: X={X_train.shape}, y={y_train.shape}\")\n",
    "            # print(f\"Loaded test: X={X_test.shape}, y={y_test.shape}\")\n",
    "\n",
    "            if X_test.shape[0] == 0:\n",
    "                raise ValueError(\"No valid test images found in the test directory!\")\n",
    "\n",
    "            X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "            y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "            X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "            y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "            # torch.save(model, os.path.join(save_path,'model_init.pt'))\n",
    "            save_path_name = os.path.join(save_path,'model_init.pt')\n",
    "            save_model(model, IMG_SIZE, N_CLASSES, LEARNING_RATE, experiment_bs, save_path_name)\n",
    "            \n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "            records = []\n",
    "\n",
    "            # Training loop\n",
    "            for epoch in range(EPOCHS):\n",
    "\n",
    "                # Train\n",
    "                model.train()\n",
    "                \n",
    "                #randomize the training data\n",
    "                perm = torch.randperm(X_train_tensor.size(0))\n",
    "                X_train_tensor = X_train_tensor[perm]\n",
    "                y_train_tensor = y_train_tensor[perm]\n",
    "\n",
    "                for start in range(0, X_train_tensor.size(0), experiment_bs):\n",
    "                    end = start + experiment_bs\n",
    "                    xb = X_train_tensor[start:end]\n",
    "                    yb = y_train_tensor[start:end]\n",
    "                    outputs = model(xb)\n",
    "                    preds = (outputs >= 0.5).float()\n",
    "                    acc_train = (preds == yb).float().mean().item()\n",
    "                    loss_train = binary_cross_entropy(outputs, yb)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss_train.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Evaluate\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(X_test_tensor)\n",
    "                    preds = (outputs >= 0.5).float()\n",
    "                    loss_test = binary_cross_entropy(outputs, y_test_tensor)\n",
    "                    acc_test = (preds == y_test_tensor).float().mean().item()\n",
    "                records.append({'poison_percent': percent_poisoned, 'epoch': epoch, \n",
    "                                'loss_train': loss_train.item(), 'acc_train': acc_train, \n",
    "                                'loss_test': loss_test.item(), 'acc_test': acc_test})\n",
    "                report_txt = f\"poison_percent {percent_poisoned} \"\n",
    "                report_txt += f\"epoch {epoch}: \"\n",
    "                report_txt += f\"loss_train={loss_train.item():.4f}, \"\n",
    "                report_txt += f\"acc_train={acc_train:.4f}, \"\n",
    "                report_txt += f\"loss_test={loss_test.item():.4f}, \"\n",
    "                report_txt += f\"acc_test={acc_test:.4f}\"\n",
    "                print(report_txt)\n",
    "\n",
    "            # torch.save(model, os.path.join(save_path,'model_last.pt'))\n",
    "            save_path_name = os.path.join(save_path,'model_last.pt')\n",
    "            save_model(model, IMG_SIZE, N_CLASSES, LEARNING_RATE, experiment_bs, save_path_name)\n",
    "\n",
    "            # Save training log\n",
    "            df = pd.DataFrame(records)\n",
    "            save_name_path = os.path.join(save_path, f'{NAME_SAVE_update_PATH}.csv')\n",
    "            df.to_csv(save_name_path, index=False)\n",
    "            print(f\"Training log saved to {save_name_path}\")\n",
    "\n",
    "            # Plot loss and accuracy\n",
    "            plt.figure(figsize=(10,4))\n",
    "\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.plot(df['epoch'], df['loss_test'], marker='o')\n",
    "            plt.title('Test Loss')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.grid(True)\n",
    "            plt.ylim(0, 1.1)\n",
    "            # plt.legend()\n",
    "\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.plot(df['epoch'], df['acc_test'], marker='o')\n",
    "            plt.title('Test Accuracy')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.grid(True)\n",
    "            plt.ylim(0, 1.1)\n",
    "            # plt.legend()\n",
    "\n",
    "            plt.tight_layout()\n",
    "            save_name_path = os.path.join(save_path, f'loss_accuracy.jpg')\n",
    "            plt.savefig(save_name_path)\n",
    "\n",
    "            save_name_path = os.path.join(save_all_path, f'{NAME_SAVE_update_PATH}_latest.jpg')\n",
    "            plt.savefig(save_name_path)\n",
    "            plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env313 (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

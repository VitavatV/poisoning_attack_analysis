# --- GLOBAL DEFAULTS ---
defaults:
  project_name: "FL_Definitive_Study_Final"
  output_dir: "./results_definitive"
  device: "cuda"
  
  # FL Settings (Standard Protocol)
  num_clients: 10
  fraction_fit: 1.0     # Full participation to reduce variance
  global_rounds: 150    # เพิ่มรอบเพื่อให้มั่นใจว่า Model Converge จริงๆ
  local_epochs: 5
  batch_size: 32  # Reduced for 8GB VRAM compatibility
  optimizer: "sgd"
  lr: 0.01
  momentum: 0.9
  weight_decay: 5e-4    # สำคัญ! Weight Decay ช่วยเรื่อง Generalization
  
  # Model Architecture
  depth: 4              # Baseline Depth
  
  # Early Stopping (Strict)
  validation_split: 0.1
  early_stopping_patience: 20  # รอให้นานขึ้นเพื่อดู Late Recovery
  min_delta: 0.0001

  # Attack Defaults
  poison_type: "label_flip"
  target_class: 0
  poison_label: 1
  poison_ratio: 0.0     # **สำคัญ** เทรนแบบ Clean Data ก่อน เพื่อดู Capacity ธรรมชาติ
  alpha: 100.0          # ใช้ IID เพื่อตัดปัจจัยข้อมูลยากออกไปก่อน
  data_ordering: "shuffle"  # Default data ordering
  aggregator: "fedavg"      # Default aggregator

# --- CRITICAL: MULTIPLE SEEDS ---
# รันทุกการทดลองซ้ำ 3-5 ครั้ง เพื่อหา Error Bar
# ถ้าค่าเฉลี่ยชนะ = ชนะจริง (Statistically Significant)
seeds: [42, 101, 2024] 

# --- EXP 0: PRELIMINARY STUDY ---
# เป้าหมาย: ดูการเติบโตของ Accuracy เมื่อเพิ่ม Width และ Depth
# เพื่อหา Regime ที่เหมาะสม (Critical vs Overparameterized)
exp0_vary_width:
  dataset: "cifar10"
  combinations:
    - width_factor: [1, 2, 4, 8, 16, 32]  # Limited to 32 for 8GB VRAM
    - depth: [2, 4, 8, 16, 32]  # Limited to 32 for 8GB VRAM
    - aggregator: ["fedavg"]


# --- EXP 1: HIGH-RESOLUTION LANDSCAPE ---
# เป้าหมาย: วาดกราฟ Double Descent ให้เนียนกริบ เพื่อหาจุด Peak ที่แท้จริง
# และพิสูจน์ว่า Width ช่วยได้จริง ไม่ใช่แค่บังเอิญ
exp1_fine_grained_width:
  dataset: "cifar10"
  combinations:
    - width_factor: [2, 4, 6, 8, 10, 12, 16, 32, 64]
    - poison_ratio: [0.0, 0.3]  # Compare clean vs attacked
    - alpha: [0.1]
    - aggregator: ["fedavg"]  # Make it a list

# --- EXP 2: DEFENSE BENCHMARK ---
# เป้าหมาย: เปรียบเทียบ Intrinsic (Width) vs Extrinsic (Median/Krum)
# ต้องพิสูจน์ว่า: Large Width + FedAvg > Small Width + FedMedian
exp2_defense_comparison:
  dataset: "cifar10"
  combinations:
    # เปรียบเทียบ 2 วิธีรวมผล
    - aggregator: ["fedavg", "median"]
    
    # เทียบจุด Critical (10) vs Robust (64)
    - width_factor: [10, 64]
    
    # Attack scenario
    - poison_ratio: [0.3]
    - alpha: [0.1]

# --- EXP 3: MECHANISM DEEP DIVE (Ordering & Batch) ---
# เป้าหมาย: ยืนยันสมมติฐาน H3.3 (Batch) และ H3.4 (Ordering)
# สิ่งนี้จะโชว์ว่าเราเข้าใจ "Why" มันถึงเกิดขึ้น
exp3_mechanism_analysis:
  dataset: "cifar10"
  combinations:
    # Vary Batch Size: เล็ก (Noise เยอะ) vs ใหญ่ (Stable)
    - batch_size: [32, 128]
    
    # Vary Ordering
    - data_ordering: ["shuffle", "bad_good", "good_bad"]
    
    # Fix ที่ Critical Regime เพื่อดูผลชัดสุด
    - width_factor: [10, 64] 
    - poison_ratio: [0.3]

# --- EXP 4: GENERALIZATION CHECK (Optional but Recommended) ---
# เป้าหมาย: ยืนยันว่าผลนี้ใช้ได้กับ Random Noise Attack ด้วย (ไม่ใช่แค่ Label Flip)
exp4_attack_types:
  dataset: "cifar10"
  combinations:
    - poison_type: ["label_flip", "random_noise"]
    - width_factor: [10, 64]
    - poison_ratio: [0.3]